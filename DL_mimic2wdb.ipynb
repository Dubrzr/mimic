{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from file_utils import *\n",
    "import lazyjson\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime\n",
    "import multiprocessing\n",
    "\n",
    "sys.setrecursionlimit(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "physioneturl = \"https://physionet.org/physiobank/database/mimic2wdb/matched\"\n",
    "db_file = 'mimic2wdb.json'\n",
    "output = 'data/mimic2wdb'\n",
    "\n",
    "create_folder(output)\n",
    "\n",
    "if not file_exists(db_file):\n",
    "    create_file(db_file, contents='{}')\n",
    "db = lazyjson.File(db_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def list_page(url, string_red=9999999, pre_idx=0):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    tmp = list(map(lambda e: e.string[:string_red], soup.find_all('pre')[pre_idx].find_all('a')))\n",
    "    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 2808 folders\n"
     ]
    }
   ],
   "source": [
    "folders = list_page(physioneturl, -1, 3)[9:]\n",
    "print('Got {} folders'.format(len(folders)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 20 files\n",
      "['3544749_0001.dat', '3544749_0001.hea', '3544749_0002.dat', '3544749_0002.hea', '3544749_0003.dat', '3544749_0003.hea', '3544749_0004.dat', '3544749_0004.hea', '3544749_0005.dat', '3544749_0005.hea', '3544749_0006.dat', '3544749_0006.hea', '3544749_0007.dat', '3544749_0007.hea', '3544749_0008.dat', '3544749_0008.hea', '3544749_layout.hea', '3544749n.dat', 's00020-2567-03-30-17-47.hea', 's00020-2567-03-30-17-47n.hea']\n"
     ]
    }
   ],
   "source": [
    "files = list_page(physioneturl + '/' + folders[0])[5:]\n",
    "print('Got {} files'.format(len(files)))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_url(f, file_url, file_path):\n",
    "    download_file(file_url, file_path)\n",
    "    h = sha256_checksum(file_path)\n",
    "    s = file_size(file_path)\n",
    "    return f, h, s\n",
    "\n",
    "def download_folder(name, processes):\n",
    "    dir_url = physioneturl + '/' + name\n",
    "    dir_path = output + '/' + name\n",
    "    \n",
    "    create_folder(dir_path)\n",
    "    if name not in db:\n",
    "        db[name] = {}\n",
    "\n",
    "    files_to_dl = []\n",
    "    for f in list_page(dir_url)[5:]:\n",
    "        if f.endswith('hea') or f.endswith('dat'):\n",
    "            file_url = dir_url + '/' + f\n",
    "            file_path = dir_path + '/' + f\n",
    "            \n",
    "            # Check local existance\n",
    "            if file_exists(file_path):\n",
    "                if f in db[name]:\n",
    "                    continue\n",
    "                    \n",
    "            delete_file(file_path)\n",
    "            files_to_dl.append((f, file_url, file_path))\n",
    "            \n",
    "    pool = multiprocessing.Pool(processes=processes) # how much parallelism?\n",
    "    try:\n",
    "        res = pool.starmap(process_url, files_to_dl)\n",
    "    except:\n",
    "        for _, _, fp in files_to_dl:\n",
    "            delete_file(fp)\n",
    "        raise\n",
    "    total_size = 0\n",
    "    total_dl = 0\n",
    "    for f, h, s in res:\n",
    "        total_size += s\n",
    "        db[name][f] = {\n",
    "            'hash': h,\n",
    "            'size': s\n",
    "        }\n",
    "        total_dl += 1\n",
    "    return total_size, total_dl\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading s00001... Done! 0/40 files downloaded/updated (0.0B in 0.74561s: 0.0B/s)\n",
      "Downloading s00020... Done! 0/20 files downloaded/updated (0.0B in 0.707867s: 0.0B/s)\n",
      "Downloading s00033... Done! 0/16 files downloaded/updated (0.0B in 0.674795s: 0.0B/s)\n",
      "Downloading s00052... Done! 0/56 files downloaded/updated (0.0B in 0.711819s: 0.0B/s)\n",
      "Downloading s00076... Done! 0/28 files downloaded/updated (0.0B in 0.698597s: 0.0B/s)\n",
      "Downloading s00079... Done! 0/78 files downloaded/updated (0.0B in 0.75301s: 0.0B/s)\n",
      "Downloading s00123... Done! 0/48 files downloaded/updated (0.0B in 0.759291s: 0.0B/s)\n",
      "Downloading s00124... Done! 0/308 files downloaded/updated (0.0B in 0.957151s: 0.0B/s)\n",
      "Downloading s00135... Done! 22/22 files downloaded/updated (14.7MiB in 8.144163s: 1.8MiB/s)\n",
      "Downloading s00138... Done! 18/18 files downloaded/updated (25.8MiB in 40.477841s: 652.0KiB/s)\n",
      "Downloading s00151... Done! 128/128 files downloaded/updated (195.5MiB in 145.757905s: 1.3MiB/s)\n",
      "Downloading s00175... Done! 2/2 files downloaded/updated (14.6KiB in 1.618067s: 9.0KiB/s)\n",
      "Downloading s00177... Done! 46/46 files downloaded/updated (32.8MiB in 21.803956s: 1.5MiB/s)\n",
      "Downloading s00184... Done! 4/4 files downloaded/updated (17.6KiB in 1.699903s: 10.4KiB/s)\n",
      "Downloading s00194... Done! 12/12 files downloaded/updated (11.6MiB in 9.635267s: 1.2MiB/s)\n",
      "Downloading s00208... Done! 80/80 files downloaded/updated (51.7MiB in 25.445756s: 2.0MiB/s)\n",
      "Downloading s00214... Done! 38/38 files downloaded/updated (103.4MiB in 47.934637s: 2.2MiB/s)\n",
      "Downloading s00217... Done! 22/22 files downloaded/updated (28.8MiB in 25.425994s: 1.1MiB/s)\n",
      "Downloading s00262..."
     ]
    }
   ],
   "source": [
    "size = 0\n",
    "for k in tmp:\n",
    "    start = datetime.datetime.now()\n",
    "    print('Downloading {}...'.format(k), end='')\n",
    "    s, dl = download_folder(k, 4)\n",
    "    elapsed = datetime.datetime.now() - start\n",
    "    total_sec = elapsed.seconds + elapsed.microseconds / 1000000\n",
    "    print(' Done! {}/{} files downloaded/updated ({} in {}s: {}/s)'.format(\n",
    "        dl,\n",
    "        len(db[k]),\n",
    "        sizeof_fmt(s),\n",
    "        total_sec,\n",
    "        sizeof_fmt(s/total_sec)\n",
    "    ))\n",
    "    \n",
    "    \n",
    "    if size > 100 * 1024**3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "for k in tmp:\n",
    "    sha256 = requests.get(physioneturl + '/' + k + '/SHA256SUMS').text\n",
    "    for l in sha256.splitlines():\n",
    "        h, f = l.split('  ')\n",
    "        if not f.endswith('hea') and not f.endswith('dat'):\n",
    "            continue\n",
    "        c += 1\n",
    "    print(c, end=\"\\r\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
