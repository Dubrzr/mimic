{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1050 Ti (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "from conf import databases, url, data_dir\n",
    "from file_utils import create_folder\n",
    "from dnn_helper import *\n",
    "\n",
    "import numpy\n",
    "import random\n",
    "import time\n",
    "\n",
    "import lasagne\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = 128\n",
    "trained_fs = 360\n",
    "min_bpm = 10\n",
    "max_bpm = 350\n",
    "min_gap = fs*60/min_bpm\n",
    "max_gap = fs*60/max_bpm\n",
    "\n",
    "# NN params\n",
    "segment_size = 5000\n",
    "segment_step = 2500\n",
    "y_delay = 0\n",
    "\n",
    "train_perc = 99\n",
    "test_perc = 100 - train_perc\n",
    "\n",
    "# Border suppression for evaluation\n",
    "left_border  = 50 # samples\n",
    "right_border = 50 # samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = 'saved-models/last'\n",
    "create_folder(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano import tensor, function, config\n",
    "from theano.tensor import basic, clip\n",
    "from lasagne.updates import adam, nesterov_momentum\n",
    "from lasagne.layers import InputLayer, DenseLayer, Conv1DLayer, BiasLayer, DropoutLayer,\\\n",
    "                           get_output, get_all_params, set_all_param_values,\\\n",
    "                           get_output_shape, ConcatLayer,get_all_param_values\n",
    "from lasagne.nonlinearities import sigmoid, rectify\n",
    "from lasagne.init import GlorotUniform\n",
    "from theano.printing import Print\n",
    "from lasagne.regularization import regularize_network_params, l2, l1\n",
    "\n",
    "def my_loss(model, predictions, targets, regularization):\n",
    "    predictions = predictions[0][0][left_border:-right_border]\n",
    "    targets = targets[0][left_border:-right_border]\n",
    "    loss = tensor.abs_(tensor.log((targets * predictions).sum() / targets.sum())) +\\\n",
    "           tensor.abs_(tensor.log(((1-targets) * (1-predictions)).sum() / (1-targets).sum()))\n",
    "    reg_loss_l1 = regularize_network_params(model, l1) * 1e-4\n",
    "    reg_loss_l2 = regularize_network_params(model, l2)\n",
    "    if regularization:\n",
    "        return loss + reg_loss_l1# + reg_loss_l2\n",
    "    else:\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, model_builder, dim, params):\n",
    "        self.t_in = tensor.ftensor3('inputs')  #  =X     float64\n",
    "        self.t_out = tensor.imatrix('targets') # =Y_true int32\n",
    "        self.input_shape = (None, dim, segment_size,)\n",
    "        self.output_shape  = (None, dim, segment_size,)\n",
    "        self.model = model_builder(self.t_in, dim=dim, shape=self.input_shape)\n",
    "        self.init_funs(self.model)\n",
    "        self.params = params\n",
    "    \n",
    "    def init_funs(self, model):\n",
    "        test_pred = get_output(self.model, deterministic=True)\n",
    "        test_loss = my_loss(self.model, test_pred, self.t_out, False)\n",
    "        test_loss_with_reg = my_loss(self.model, test_pred, self.t_out, True)\n",
    "        test_acc  = tensor.mean(tensor.eq(tensor.argmax(test_pred, axis=1), self.t_out), dtype=config.floatX)\n",
    "        \n",
    "        self.eval_fn  = function([self.t_in, self.t_out], [test_loss, test_loss_with_reg, test_acc], allow_input_downcast=True)\n",
    "        self.evaluate = function([self.t_in], get_output(self.model, self.t_in), allow_input_downcast=True)\n",
    "        \n",
    "        pred = get_output(self.model)\n",
    "        loss_with_reg = my_loss(self.model, pred, self.t_out, True)\n",
    "        params = get_all_params(self.model, trainable=True)\n",
    "        updates = adam(loss_with_reg, params=params, learning_rate=0.0001)\n",
    "        self.train_fn = function([self.t_in, self.t_out], loss_with_reg, updates=updates, allow_input_downcast=True)\n",
    "    \n",
    "    def train(self, train_exs, test_exs, num_epochs, examples_by_epoch, stop_accuracy=100.0, info=False):\n",
    "        trainN, testN = len(train_exs), len(test_exs)\n",
    "        print('Training on {} examples, testing on {} examples.'.format(trainN, testN))\n",
    "        print(\"Starting training...\")\n",
    "        \n",
    "        ex_count = 0\n",
    "        train_losses = []\n",
    "        rps = []\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            if epoch < 5:\n",
    "                train_losses = []\n",
    "            start_time = time.time()\n",
    "            print('Epoch {}/{} running...'.format(epoch, num_epochs), end='')\n",
    "            train_loss = 0\n",
    "            train_loss_with_reg = 0\n",
    "            invalid_example = 0\n",
    "            for z in range(examples_by_epoch):\n",
    "                db, i, j = train_exs[ex_count%trainN]\n",
    "                XY = load_steps(db, i, *self.params)[j]\n",
    "                x, y = numpy.reshape(XY[0], (1, 1, 5000)).astype('float16'), numpy.reshape(XY[1], (1, 5000)).astype('float16')\n",
    "                ex_count += 1\n",
    "                if numpy.sum(y) == 0.:\n",
    "                    invalid_example += 1\n",
    "                    continue\n",
    "                tmp_loss = self.train_fn(x, y)\n",
    "                train_loss += tmp_loss\n",
    "                train_losses.append(train_loss/(z+1-invalid_example))\n",
    "            print('Done in {:.3f}s!'.format(time.time() - start_time))\n",
    "            print(\"  - training loss:\\t\\t{:.6f}\".format(train_loss / (examples_by_epoch-invalid_example)))\n",
    "            \n",
    "            # Eval on examples:\n",
    "            test_loss = 0\n",
    "            test_reg_loss = 0\n",
    "            test_acc = 0\n",
    "            invalid_example = 0\n",
    "            for k in range(testN):\n",
    "                db, i, j = train_exs[k]\n",
    "                XY = load_steps(db, i, *self.params)[j]\n",
    "                x, y = numpy.reshape(XY[0], (1, 1, 5000)).astype('float16'), numpy.reshape(XY[1], (1, 5000)).astype('float16')\n",
    "                if numpy.sum(y) == 0.:\n",
    "                    invalid_example += 1\n",
    "                    continue\n",
    "                tmp_loss, tmp_reg_loss, tmp_acc = self.eval_fn(x, y)\n",
    "                test_loss += tmp_loss\n",
    "                test_reg_loss += (tmp_reg_loss-tmp_loss)\n",
    "                test_acc  += tmp_acc\n",
    "            N = (testN-invalid_example)\n",
    "            print(\"  - test loss:\\t\\t\\t{:.6f} | {:.6f} | {:.6f}\".format(test_loss / N, test_reg_loss / N, (test_loss+test_reg_loss) / N))\n",
    "            acc = test_acc / N * 100\n",
    "            print(\"  - test accuracy:\\t\\t{:.4f} %\".format(acc))\n",
    "            plt.plot(train_losses, color='r')\n",
    "            plt.plot(rps, color='g')\n",
    "            plt.show()\n",
    "            eval_model(test_exs, self.evaluate, min_gap, max_gap, left_border, right_border, *self.params,\n",
    "                       plot_examples=True, nb=3, nearest_fpr=0.01, threshold=0.95, eval_margin=10)\n",
    "            save_model(model_path + '/model-loss{}-epoch{}.sav'.format(test_loss / N, epoch), self.model, get_all_param_values(self.model))\n",
    "            if acc > stop_accuracy:\n",
    "                break\n",
    "    \n",
    "    def eval_data(self, x, fs_target):\n",
    "        fs_target, y_delay, segment_size, segment_step, normalized_steps = self.params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model shape:\n",
      "  Layer A:\n",
      "    a1: (None, 8, 5000)\n",
      "    a2: (None, 64, 5000)\n",
      "    a3: (None, 64, 5000)\n",
      "    a4: (None, 32, 5000)\n",
      "    a5: (None, 16, 5000)\n",
      "    a6: (None, 16, 5000)\n",
      "    a7: (None, 16, 5000)\n",
      "   al: (None, 216, 5000)\n",
      "  Layer B:\n",
      "    b1: (None, 8, 5000)\n",
      "    b2: (None, 64, 5000)\n",
      "    b3: (None, 64, 5000)\n",
      "    b4: (None, 64, 5000)\n",
      "   bl: (None, 136, 5000)\n",
      "  Layer C:\n",
      "    c1: (None, 8, 5000)\n",
      "    c2: (None, 32, 5000)\n",
      "    c3: (None, 32, 5000)\n",
      "    c4: (None, 32, 5000)\n",
      "    c5: (None, 32, 5000)\n",
      "   cl: (None, 136, 5000)\n",
      "  Layer D:\n",
      "    d1: (None, 8, 5000)\n",
      "    d2: (None, 32, 5000)\n",
      "    d3: (None, 64, 5000)\n",
      "   dl: (None, 104, 5000)\n",
      "  Later E:\n",
      "    e1: (None, 16, 5000)\n",
      "    e2: (None, 16, 5000)\n",
      "    e3: (None, 16, 5000)\n",
      "   el: (None, 48, 5000)\n",
      "  Layer F:\n",
      "    f1: (None, 8, 5000)\n",
      "    f2: (None, 16, 5000)\n",
      "    f3: (None, 16, 5000)\n",
      "   fl: (None, 40, 5000)\n",
      "  Layer G:\n",
      "    g1: (None, 1, 5000)\n",
      "   gl: (None, 1, 5000)\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_tensor, dim, shape=None):\n",
    "    print('Model shape:')\n",
    "    \n",
    "    l_in = InputLayer(shape, input_var=input_tensor)\n",
    "    \n",
    "    print('  Layer A:')\n",
    "    a1 = Conv1DLayer(l_in, num_filters=8, filter_size=(3), nonlinearity=rectify, pad='same')\n",
    "    print('    a1:', get_output_shape(a1))\n",
    "    a2 = Conv1DLayer(l_in, num_filters=64, filter_size=(15), nonlinearity=rectify, pad='same')\n",
    "    print('    a2:', get_output_shape(a2))\n",
    "    a3 = Conv1DLayer(l_in, num_filters=64, filter_size=(45), nonlinearity=rectify, pad='same')\n",
    "    print('    a3:', get_output_shape(a3))\n",
    "    a4 = Conv1DLayer(l_in, num_filters=32, filter_size=(89), nonlinearity=rectify, pad='same')\n",
    "    print('    a4:', get_output_shape(a4))\n",
    "    a5 = Conv1DLayer(l_in, num_filters=16, filter_size=(149), nonlinearity=rectify, pad='same')\n",
    "    print('    a5:', get_output_shape(a5))\n",
    "    a6 = Conv1DLayer(l_in, num_filters=16, filter_size=(199), nonlinearity=rectify, pad='same')\n",
    "    print('    a6:', get_output_shape(a6))\n",
    "    a7 = Conv1DLayer(l_in, num_filters=16, filter_size=(299), nonlinearity=rectify, pad='same')\n",
    "    print('    a7:', get_output_shape(a7))\n",
    "    al = ConcatLayer([a1, a2, a3, a4, a5, a6, a7], axis=1)\n",
    "    print('   al:', get_output_shape(al))\n",
    "\n",
    "    ad = DropoutLayer(al, p=0.5)\n",
    "\n",
    "    print('  Layer B:')\n",
    "    b1 = Conv1DLayer(ad, num_filters=8, filter_size=3, nonlinearity=rectify, pad='same')\n",
    "    print('    b1:', get_output_shape(b1))\n",
    "    b2 = Conv1DLayer(ad, num_filters=64, filter_size=9, nonlinearity=rectify, pad='same')\n",
    "    print('    b2:', get_output_shape(b2))\n",
    "    b3 = Conv1DLayer(ad, num_filters=64, filter_size=19, nonlinearity=rectify, pad='same')\n",
    "    print('    b3:', get_output_shape(b3))\n",
    "    b4 = Conv1DLayer(ad, num_filters=64, filter_size=39, nonlinearity=rectify, pad='same')\n",
    "    print('    b4:', get_output_shape(b4))\n",
    "    bl = ConcatLayer([b1, b2, b3], axis=1)\n",
    "    print('   bl:', get_output_shape(bl))\n",
    "    \n",
    "    bd = DropoutLayer(bl, p=0.5)\n",
    "\n",
    "    print('  Layer C:')\n",
    "    c1 = Conv1DLayer(bd, num_filters=8, filter_size=3, nonlinearity=rectify, pad='same')\n",
    "    print('    c1:', get_output_shape(c1))\n",
    "    c2 = Conv1DLayer(bd, num_filters=32, filter_size=5, nonlinearity=rectify, pad='same')\n",
    "    print('    c2:', get_output_shape(c2))\n",
    "    c3 = Conv1DLayer(bd, num_filters=32, filter_size=9, nonlinearity=rectify, pad='same')\n",
    "    print('    c3:', get_output_shape(c3))\n",
    "    c4 = Conv1DLayer(bd, num_filters=32, filter_size=15, nonlinearity=rectify, pad='same')\n",
    "    print('    c4:', get_output_shape(c4))\n",
    "    c5 = Conv1DLayer(bd, num_filters=32, filter_size=19, nonlinearity=rectify, pad='same')\n",
    "    print('    c5:', get_output_shape(c5))\n",
    "    cl = ConcatLayer([c1, c2, c3, c4, c5])\n",
    "    print('   cl:', get_output_shape(cl))\n",
    "    \n",
    "    cd = DropoutLayer(cl, p=0.4)\n",
    "    \n",
    "    print('  Layer D:')\n",
    "    d1 = Conv1DLayer(cd, num_filters=8, filter_size=3, nonlinearity=rectify, pad='same')\n",
    "    print('    d1:', get_output_shape(d1))\n",
    "    d2 = Conv1DLayer(cd, num_filters=32, filter_size=5, nonlinearity=rectify, pad='same')\n",
    "    print('    d2:', get_output_shape(d2))\n",
    "    d3 = Conv1DLayer(cd, num_filters=64, filter_size=15, nonlinearity=rectify, pad='same')\n",
    "    print('    d3:', get_output_shape(d3))\n",
    "    dl = ConcatLayer([d1, d2, d3])\n",
    "    print('   dl:', get_output_shape(dl))\n",
    "    \n",
    "    dd = DropoutLayer(dl, p=0.3)\n",
    "    \n",
    "    print('  Later E:')\n",
    "    e1 = Conv1DLayer(dd, num_filters=16, filter_size=5, nonlinearity=rectify, pad='same')\n",
    "    print('    e1:', get_output_shape(e1))\n",
    "    e2 = Conv1DLayer(dd, num_filters=16, filter_size=15, nonlinearity=rectify, pad='same')\n",
    "    print('    e2:', get_output_shape(e2))\n",
    "    e3 = Conv1DLayer(dd, num_filters=16, filter_size=19, nonlinearity=rectify, pad='same')\n",
    "    print('    e3:', get_output_shape(e3))\n",
    "    el = ConcatLayer([e1, e2, e3])\n",
    "    print('   el:', get_output_shape(el))\n",
    "    \n",
    "    ed = DropoutLayer(el, p=0.2)\n",
    "    \n",
    "    print('  Layer F:')\n",
    "    f1 = Conv1DLayer(ed, num_filters=8, filter_size=3, nonlinearity=rectify, pad='same')\n",
    "    print('    f1:', get_output_shape(f1))\n",
    "    f2 = Conv1DLayer(ed, num_filters=16, filter_size=9, nonlinearity=rectify, pad='same')\n",
    "    print('    f2:', get_output_shape(f2))\n",
    "    f3 = Conv1DLayer(ed, num_filters=16, filter_size=15, nonlinearity=rectify, pad='same')\n",
    "    print('    f3:', get_output_shape(f3))\n",
    "    fl = ConcatLayer([f1, f2, f3])\n",
    "    print('   fl:', get_output_shape(fl))\n",
    "    \n",
    "    fd = DropoutLayer(fl, p=0.1)\n",
    "    \n",
    "    print('  Layer G:')\n",
    "    g1 = Conv1DLayer(fd, num_filters=1, filter_size=3, nonlinearity=sigmoid, pad='same')\n",
    "    print('    g1:', get_output_shape(g1))\n",
    "    gl = ConcatLayer([g1])\n",
    "    print('   gl:', get_output_shape(gl))\n",
    "    \n",
    "    return gl\n",
    "\n",
    "\n",
    "nn = NN(dim=1, model_builder=build_model, params=(360, 0, 5000, 2500, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 102018 (510090000 samples)\n",
      "          Training: 100997 (504985000 samples)\n",
      "           Testing: 1021 (5105000 samples)\n"
     ]
    }
   ],
   "source": [
    "exs = shuffled_examples(360, 0, 5000, 2500, False)\n",
    "train_exs = exs[:int(len(exs)*train_perc/100)]\n",
    "test_exs  = exs[int(len(exs)*train_perc/100):]\n",
    "print('Number of examples: {} ({} samples)'.format(len(exs), len(exs)*5000))\n",
    "print('          Training: {} ({} samples)'.format(len(train_exs), len(train_exs)*5000))\n",
    "print('           Testing: {} ({} samples)'.format(len(test_exs), len(test_exs)*5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn.train(train_exs, test_exs, num_epochs=400, examples_by_epoch=1000, info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, params = load_model(model_path + '/model-loss0.037631392673427445-epoch1200.sav')\n",
    "# print(params)\n",
    "set_all_param_values(nn.model, params)\n",
    "nn.init_funs(nn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_model(testXY, nn.evaluate, left_border=left_border, right_border=right_border,\n",
    "           min_gap=min_gap, max_gap=max_gap, plot_examples=True, nb=10,\n",
    "           nearest_fpr=0.000675, threshold=0.9678147, eval_margin=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
